<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>reveal.js</title>

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/custom.css">
    <link rel="stylesheet" href="css/theme/black.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
		var link = document.createElement('link');
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
		document.getElementsByTagName('head')[0].appendChild(link);










    </script>
</head>

<body>
<div class="reveal">
    <!-- Any section element inside of this container is displayed as a slide -->
    <div class="slides">
        <section data-background="#FFFFFF" data-transition="none">
            <h2>INTELIGENTNY KOSZYK <br>NA ZAKUPY</h2>
            <h4>STUDIUM PRZYPADKU<br>DEEP LEARNING - INTEL MOVIDIUS - AWS</h4>
			<img data-src="img/Capgemini.jpg">
			<aside class="notes">
				<ul>
					<li>Obserwowalny trend - narzędzia ML w chmurze: AWS, Azure, itp., ale z drugiej strony Edge Computing.</li>
					<li>Narzędzia są coraz bardziej przyjazne dla użytkownika (przykłady: Rapid Miner, KNIME, H20.ai).</li>
					<li>Rozwijające się specjalizacje AI: NLP, Computer Vision, Cognitive RPA, Conversational User Interfaces/Chatbots, etc.</li>
					<li>Coraz szersze zastosowania: finanse i księgowość, HR (talent management, attrition prediction, optymalizacja kosztów, automatyzacja procesów --> AId4Dispatcher), </li>
					<li>Ciekawe przypadki użycia w Capgemini: https://youtu.be/M5y1eeAgaUg</li>
					<li>Z drugiej strony - "hype" jest w tej chwili "rozdmuchany" - sprzedawcy do wszystkiego, co się da dodają etykietę "AI", mimo, że nie zawsze ma to uzasadnienie.</li>
				</ul>
			</aside>
        </section>

		<section data-background="#FFFFFF" data-transition="none">
			<img width="800" data-src="img/logo-data-science-community-01.png">
			<aside class="notes">
				NSC  -  techniczne rozwiązania AI. Rozwijamy nasze kompetencje w tym zakresie w Data Science Community: uczymy się wzajemnie tego, co udało nam się poznać w różnego rodzaju projektach, organizujemy szkolenia, jeździmy na konferencje, a także wystawiamy zespoły do wewnętrznych hackathonów i innych konkursów.
			</aside>
        </section>
		
		<!-- Motivation. -->
		<section data-background="#FFFFFF" data-transition="none">
            <h3>Hackathon Capgemini - AI4CHANGE</h3>
			<img width="800" data-src="img/AI4CHANGE.png">
			<aside class="notes">
				Globalnie Capgemini widzi trendy w obszarze AI i intensywnie pracuje nad rozwojem w tym zakresie. Regularnie odbywają się konkursy (hackathony, data science challenges, etc.). AI4CHANGE był kolejnym hackathonem, zorganizowanym globalnie - uczestniczyło w nim ok. 100 zespołów z niemal wszystkich krajów, w których Capgemini jest obecne (ze wszystkich kontynentów poza Antarktydą ;-)).  
			</aside>
        </section>
		
		<!-- Who we are? -->
		<section data-background="#FFFFFF" data-transition="none">
            <h3>Team</h3>
			<img width="800" data-src="img/team.png">
			<aside class="notes">
				Na AI4CHANGE nie mogło zabraknąć zespołu złożonego z członków DSC. 
			</aside>
        </section>
		
		
		<!-- Motivation. -->
		<section data-background="#FFFFFF" data-transition="none">
            <h3>Nasza motywacja</h3>
			<div class="leftContent2">
				<!-- Image source: https://pixabay.com/de/gehirn-geist-psychologie-idee-2062057/ -->
				<img width="900" data-src="img/brain-2062057_640.jpg">
			</div>
			<div class="rightContent2">
				<ul>
					<li>
						<div class="small">
							<p class="fragment">temat miał być związany z AI
							<p>
						</div>
					</li>
					<li>
						<div class="small">
							<p class="fragment">nasz pierwszy wybór: obszar biznesowy dot. koszyków zakupowych
							<p>
						</div>
					</li>
					<li>
						<div class="small">
							<p class="fragment">nasz drugi wybór: IoT i Edge Computing 
							<p>
						</div>
					</li>
					<li>
						<div class="small">
							<p class="fragment">nasz trzeci wybór: AWS
							<p>
						</div>
					</li>
				</ul>
			</div>
        </section>
		
        <!-- Introduction - online vs offline retailers-->
        <section data-background="#FFFFFF" data-transition="none">
            <h4>Dlaczego zakupy detaliczne?</h4>
			<div class="leftContent2">
				<!-- Image source: https://pixabay.com/de/einkaufen-geschäft-einzelhandel-1165437/ -->
				<img width="900" data-src="img/shopping-1165437_640.jpg">
			</div>
			<div class="rightContent2">
				<ul>
					<li>
						<div class="small">
							<p class="fragment">...bo widzieliśmy problem: jak zrealizować rekomendowanie produktów?  
							<p>
						</div>
					</li>
					<li>
						<div class="small">
							<p class="fragment">...bo widzieliśmy szansę: dobry obszar do stosowania IoT
							<p>
						</div>
					</li>
				</ul>
			</div>
		</section>
		
        <!-- Recommendations-->
        <section data-background="#FFFFFF" data-transition="none">
            <h3>Coś co jest oczywiste w sklepie on-line...</h3>
            <div>
                <img width="800" data-src="img/recommendations.png">
				<p>...jest sporym wyzwaniem w sklepie off-line. 
            </div>
        </section>
		
        <!-- Introduction - online vs offline retailers-->
        <section data-background="#FFFFFF" data-transition="none">
            <h3>Jak to robią inni?</h3>
            <div>
                <div class="leftContent2">
                    <img width="900" height="490" data-src="img/old_fashioned_shopping_cart.png">
                </div>
                <div class="rightContent2">
                    <ul>
						<li>grudzień 2016 - Amazon otwiera pierwszy sklep detaliczny pod marką Amazon Go (w wersji beta)</li>
						<li>wrzesień 2018 - Microsoft i Żabka prezentują koncept "sklepu jutra"</li>
					</ul>
                </div>
            </div>
			<aside class="notes">
				<ul>
					<li>https://youtu.be/NrmMk1Myrxc</li>
					<li> https://news.microsoft.com/pl-pl/2018/09/14/zabka-wskazuje-przyszlosc-handlu-wspolnie-z-microsoft-prezentuje-innowacyjny-koncept-sklepu/</li>
					<li>https://www.zabka.pl/biuro-prasowe/zabka-wskazuje-przyszlosc-handlu-wspolnie-z-microsoft-prezentuje-innowacyjny-koncept-sklepu</li>
				</ul>
			</aside>
        </section>
		
        <section data-background="#FFFFFF" data-transition="none">
			<h3>A dlaczego Edge Computing?</h3>
            <img width="800" data-src="img/tweet.png">			
        </section>
		
        <section data-background="#FFFFFF" data-transition="none">
            <h3>Wyzwania implementacyjne w przenoszeniu AI/ML do Edge:</h3>
            <ul>
                <li>
                    <div class="small">
                        <p class="fragment">rozmiary modeli
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">dostępna moc obliczeniowa
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">konsumpcja energii
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">niska dokładność prostych modeli 
                        <p>
                    </div>
                </li>
            </ul>
        </section>
		
        <section data-transition="none" data-background="#FFFFFF">
            <h3>Po co jeszcze do tego używać AWS?</h3>
            <ul>
                <li>
                    <div class="small">
                        <p class="fragment">centralna baza danych (produkty i koszyki)
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">centralna definicja logiki biznesowej
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">monitoring działania systemu
                        <p>
                    </div>
                </li>
            </ul>
        </section>
        
		<section data-background="#FFFFFF" data-transition="none">
            <h3>Architektura - wersja docelowa</h3>
            <img width="900" height="230" data-src="img/architecture_high_level_6.png">
        </section>
        
		<section data-background="#FFFFFF" data-transition="none">
            <h3>Architektura - PoC</h3>
            <img width="900" height="230" data-src="img/architecture_high_level_5.png">
        </section>
        
		<section data-background="#FFFFFF" data-transition="none">
            <img width="900" height="490" data-src="img/movidius_raspberry.png">
        </section>
        
		<section data-background="#FFFFFF" data-transition="none">
            <h3>Intel® Movidius™ Neural Compute Stick</h3>
            <div>
                <div class="leftContent2">
                    <img width="420" height="320" data-src="img/movidius.png">
                </div>
                <div class="rightContent2">
                    <p>Mały, energooszczędny, <br>w formie pendrive'a, <br>służy do&nbsp;eksperymentowania i&nbsp;nauki w obszarze stosowania AI w&nbsp;modelu Edge Computing.</p>
                </div>
            </div>
            <aside class="notes">
                Przeniesienie obliczeń z chmury na "edge"
            </aside>
        </section>
        
		<section data-background="#053d6f" data-transition="none">
            <h3>Intel® Movidius™ NCS - kluczowe cechy</h3>
            <ul>
                <li>
                    <div class="small">
                        <p class="fragment">ultra-niski pobór mocy
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">konstrukcja ukierunkowana na przetwarzanie obrazów oraz AI
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">małe rozmiary
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">dostępne frameworki: TensorFlow, Caffe
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">wyniki obliczeń dostępne w czasie rzeczywistym (brak wymogu łączności z chmurą) 
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">skalowalność - możliwość użycia wielu urządzeń równolegle na tej samej platformie
                        <p>
                    </div>
                </li>
            </ul>
            <aside class="notes">
                An ultra-low power design - For mobile and connected devices where battery life is critical, Myriad 2
                provides a way to combine advanced vision applications in a low power profile. Intel's Movidius™ Myriad™
                2 VPU delivers vision capabilities to
                classes of devices previously unable to perform such demanding vision tasks.
                Unique design for vision and AI workloads - Featuring 12 VLIW programmable SHAVE cores, dedicated vision
                accelerators and 2 CPUS, all connected by an intelligent memory fabric, Intel's Movidius™ Myriad™ 2 VPU
                is a fully functional vision SoC
                designed for high performance at ultra-low power. The highly parallel design and optimizations for
                sparse data structures make Myriad VPUs well suited to deep neural network applications and other modern
                vision workloads.
                12 programmable SHAVE cores - The flexibility for developers to implement differentiated and proprietary
                applications is fundamental to Intel® Movidius™ Myriad™ 2 VPUs. Our optimized software libraries give
                device manufacturers the ability to
                run custom and proprietary operations on the 12 high performance SHAVE cores.
                A small-area footprint - To conserve space inside mobile, wearable, and embedded devices, Intel's
                Movidius™ Myriad™ 2 was designed with a very small footprint that can easily be integrated into existing
                products.
            </aside>
        </section>
        
		<section data-background="#053d6f" data-transition="none">
          <h3>Jakie są możliwości Intel Movidius NCS?</h3>
        </section>
		
        <!-- plik guitar.mov -->
		<!--
		<section data-background="#000000" data-background-video="img/guitar.mov" data-background-size="contain" data-transition="none">
        </section> 
		-->
        <section data-background="#053d6f" data-transition="none">
            <h3>Intel® Movidius™ NCS</h3>
            <div class="leftContent2">
                <img width="490" height="330" data-src="img/shark_spotter.jpg">
            </div>
            <div class="rightContent2">
                <div class="small">
                    <p class="fragment">Możliwe zastosowania:
                    <p>
                </div>
                <ul>
                    <li>
                        <div class="small">
                            <p class="fragment">detekcja obiektów
                            <p>
                        </div>
                    </li>
                    <li>
                        <div class="small">
                            <p class="fragment">klasyfikacja obiektów
                            <p>
                        </div>
                    </li>
                    <li>
                        <div class="small">
                            <p class="fragment">rozpoznawanie twarzy
                            <p>
                        </div>
                    </li>
                    <li>
                        <div class="small">
                            <p class="fragment">przetwarzanie języka naturalnego
                            <p>
                        </div>
                    </li>
                </ul>
            </div>
        </section>
        
		<section data-transition="none">
            <h3>YOLO: wykrywanie obiektów w czasie rzeczywistym</h3>
        </section>
        
		<section data-transition="none">
            <h3>Jak działa YOLO?</h3>
            <div>
                <div class="leftContent2">
                    <img width="420" height="420" data-src="img/products.jpg">
                </div>
                <div class="rightContent2">
                    <p>obraz wyjściowy</p>
                </div>
            </div>
        </section>
        
		<section data-transition="none">
            <h3>Jak działa YOLO?</h3>
            <div>
                <div class="leftContent2">
                    <img width="420" height="420" data-src="img/products_grid.jpg">
                </div>
                <div class="rightContent2">
                    <p>obraz podzielony na mniejsze elementy (siatkę)</p>
                </div>
            </div>
        </section>
        
		<section data-transition="none">
            <h3>Jak działa YOLO?</h3>
            <div>
                <div class="leftContent2">
                    <img width="420" height="420" data-src="img/products_oshee_red.jpg">
                </div>
                <div class="rightContent2">
                    <p>każdy z elementów służy do estymacji położenia i rozmiarów prostokąta ograniczającego obiekt oraz miary ufności obliczanej na podstawie p-stwa wystąpienia obiektu</p>
                </div>
            </div>
        </section>
		
        <section data-transition="none">
            <h3>Jak działa YOLO?</h3>
            <div>
                <div class="leftContent2">
                    <img width="420" height="420" data-src="img/products_oshee_bound.jpg">
                </div>
                <div class="rightContent2">
                    <p>każdy z elementów służy do estymacji położenia i rozmiarów prostokąta ograniczającego obiekt oraz miary ufności obliczanej na podstawie p-stwa wystąpienia obiektu</p>
                </div>
            </div>
        </section>
		
        <section data-transition="none">
            <h3>Jak działa YOLO?</h3>
            <div>
                <div class="leftContent2">
                    <img width="420" height="420" data-src="img/products_empty_red.jpg">
                </div>
                <div class="rightContent2">
                    <p>każdy z elementów służy do estymacji położenia i rozmiarów prostokąta ograniczającego obiekt oraz miary ufności obliczanej na podstawie p-stwa wystąpienia obiektu</p>
                </div>
            </div>
        </section>
		
        <section data-transition="none">
            <h3>Jak działa YOLO?</h3>
            <div>
                <div class="leftContent2">
                    <img width="420" height="420" data-src="img/products_empty_bound.jpg">
                </div>
                <div class="rightContent2">
                    <p>każdy z elementów służy do estymacji położenia i rozmiarów prostokąta ograniczającego obiekt oraz miary ufności obliczanej na podstawie p-stwa wystąpienia obiektu</p>
                </div>
            </div>
        </section>
		
        <section data-transition="none">
            <h3>Jak działa YOLO?</h3>
            <div>
                <div class="leftContent2">
                    <img width="420" height="420" data-src="img/products_empty_bound_grid.jpg">
                </div>
                <div class="rightContent2">
                    <p>każdy z elementów służy do estymacji położenia i rozmiarów prostokąta ograniczającego obiekt oraz miary ufności obliczanej na podstawie p-stwa wystąpienia obiektu</p>
                </div>
            </div>
        </section>
		
        <section data-transition="none">
            <h3>Jak działa YOLO?</h3>
            <div>
                <div class="leftContent2">
                    <img width="420" height="420" data-src="img/products_boundes.jpg">
                </div>
                <div class="rightContent2">
                    <p>każdy z elementów służy do estymacji położenia i rozmiarów prostokąta ograniczającego obiekt oraz miary ufności obliczanej na podstawie p-stwa wystąpienia obiektu</p>
                </div>
            </div>
        </section>
		
        <section data-transition="none">
            <h3>Jak działa YOLO?</h3>
            <div>
                <div class="leftContent2">
                    <img width="420" height="420" data-src="img/products_grid.jpg">
                </div>
                <div class="rightContent2">
                    <p>każdy z elementów służy także do estymacji prawdopodobieństwa przynależności obiektu do danej klasy</p>
                </div>
            </div>
        </section>
		
        <section data-transition="none">
            <h3>Jak działa YOLO?</h3>
            <div>
                <div class="leftContent2">
                    <img width="420" height="420" data-src="img/products_boundes.jpg">
                </div>
                <div class="rightContent2">
                    <img width="420" height="420" data-src="img/products_grid_color.jpg">
                </div>
            </div>
        </section>
		
        <section data-transition="none">
            <h3>Jak działa YOLO?</h3>
            <div>
                <div class="leftContent2">
                    <img width="420" height="420" data-src="img/products_boundes_color.jpg">
                </div>
                <div class="rightContent2">
                    <p>w kolejnym kroku miary ufności dla prostokątów ograniczających obiekt są mnożone przez prawdopodobieństwa przynależności obiektu do klasy</p>
                </div>
            </div>
        </section>
		
        <section data-transition="none">
            <h3>Jak działa YOLO?</h3>
            <div>
                <div class="leftContent2">
                    <img width="420" height="420" data-src="img/products_result_color.jpg">
                </div>
                <div class="rightContent2">
                    <p>w ostatnim kroku odrzuca się detekcje, dla których wcześniej wyliczona wartość jest niższa niż zadany próg</p>
                </div>
            </div>
        </section>
		
        <section data-transition="none">
            <h3>Jak wyszkolić algorytm YOLO?</h3>
        </section>
		
		<!-- plik darknet.mov -->
		<!--
        <section data-background="#000000" data-background-video="img/darknet.mov" data-background-size="contain" data-transition="none">
        </section>
		-->
        <section data-background="#053d6f" data-transition="none">
            <h3>Jak przenieść wyszkolony algorytm</br>na Intel Movidius NCS?</h3>
        </section>
		
		<!-- plik movidius.mov -->
		<!--
        <section data-background="#000000" data-background-video="img/movidius.mov" data-background-size="contain" data-transition="none">
        </section>
		-->
        <section data-transition="none">
            <h3>Jak ocenić działający algorytm</br>na Raspberry Pi?</h3>
        </section>
		
		<!-- plik raspberry.mov -->
		<!--
        <section data-background="#000000" data-background-video="img/raspberry.mov" data-background-size="contain" data-transition="none">
        </section>
		-->

        <!-- Architecture overview - high-level -->
        <section data-background="#FFFFFF" data-transition="none">
            <img width="900" height="230" data-src="img/architecture_high_level_1.png">
        </section>

        <section data-background="#FFFFFF" data-transition="none">
            <h3>AWS IoT Core</h3>
            <ul>
                <li>
                    <div class="small">
                        <p class="fragment">pozwala na interakcję urządzeń IoT z chmurą 
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">pozwala na dwukierunkową komunikację 
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">implementuje protokoły: MQTT, HTTP, MQTT + WebSocket
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">umożliwia stosowanie paradygmatu serverless
                        <p>
                    </div>
                </li>
            </ul>
        </section>

		<section data-transition="none" data-background="#FFFFFF">
			<h3>MQTT</h3>
			<img data-src="img/MQTTCapture.PNG">
			<aside class="notes">
				MQTT = Message Queuing Telemetry Transport; standard ISO/IEC PRF 20922; zdefiniowany w 1999 roku przez IBM i Cirrus Link.
			</aside>
		</section>

        <section data-background="#FFFFFF" data-transition="none">
            <img width="900" height="230" data-src="img/architecture_high_level_2.png">
        </section>
		
        <section data-transition="none">
            <h3>Komunikacja: z sensora do chmury</h3>
            <div class="small">
                <pre><code>
{
  "product": "tomato"
}
				</code></pre>
            </div>
			<aside class="notes">
				Urządzenie z sensorem (koszyk) wysyła taki komunikat na kanale products.
			</aside>
        </section>

        <section data-background="#FFFFFF" data-transition="none">
            <img width="900" height="230" data-src="img/architecture_high_level_3.png">
        </section>
		
        <section data-background="#FFFFFF" data-transition="none">
            <h3>AWS Lambda</h3>
            <ul>
                <li>
                    <div class="small">
                        <p class="fragment">pozwala uruchamiać niewielkie fragmenty kodu w chmurze, bez konieczności utrzymywania własnego serwera
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">obliczenia wykonywane są natychmiast 
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">kod jest uruchamiany tylko w razie potrzeby 
                        <p>
                    </div>
                </li>
            </ul>
			<aside class="notes">
				To tylko alternatywa na potrzeby PoC. Docelowe rozwiązanie: SageMaker.
			</aside>
        </section>

        <section data-background="#FFFFFF" data-transition="none">     
            <img width="900" height="230" data-src="img/architecture_high_level_4.png">
        </section>
		
        <section data-background="#FFFFFF" data-transition="none">
            <img width="900" height="230" data-src="img/architecture_high_level_5.png">
        </section>

        <section data-transition="none">
            <h3>Komunikacja: z chmury do urządzenia</h3>
            <div class="small">
                <pre><code>
{
  "output": {
    "recommendation": "cucumber"
  }
}
				</code></pre>
            </div>
			<aside class="notes">
				Taki komunikat wysyła AWS do koszyka korzystając z kanału advice.
			</aside>
        </section>

		<section data-transition="none" data-background="#FFFFFF">
			<h3>Jak to "wyklikać" w AWS?</h3>
			<img data-src="img/AWS1Capture.PNG">
			<aside class="notes">
				Po pierwsze potrzebujemy wirtualnej reprezentacji naszego urządzenia. W AWS takie obiekty nazywają się "Things".
			</aside>
		</section>
		<section data-transition="none" data-background="#FFFFFF">
			<h3>Jak to "wyklikać" w AWS?</h3>
			<img data-src="img/AWS2Capture.PNG">
			<aside class="notes">
				Z takim obiektem należy skojarzyć certyfikat, który pozwoli identyfikować urządzenie (certyfikaty trzeba wgrać w postaci plików na Raspberry Pi).
			</aside>
		</section>
		<section data-transition="none" data-background="#FFFFFF">
			<h3>Jak to "wyklikać" w AWS?</h3>
			<img data-src="img/AWS3Capture.PNG">
			<aside class="notes">
				Reakcje na komunikaty przychodzące definiuje się jako "Rules". 
			</aside>
		</section>
		<section data-transition="none" data-background="#FFFFFF">
			<h3>Jak to "wyklikać" w AWS?</h3>
			<img data-src="img/AWS4Capture.PNG">
			<aside class="notes">
				Taką regułę można zdefiniować korzystając z uproszczonego dialektu SQL. Wiadomości są dostarczane w tabeli o takiej nazwie jak nazwa kanału. Przetwarzając dane można korzystać z Lambdy lub SageMakera.<br><br>
				W regule wybiera się też, co ma się stać z tak przetworzonymi danymi. Tutaj wysyłane się do brokera MQTT w kanale advice.
			</aside>			
		</section>
		<section data-transition="none" data-background="#FFFFFF">
			<h3>Jak to "wyklikać" w AWS?</h3>
			<img data-src="img/AWS5Capture.PNG">
			<aside class="notes">
				Ważny aspekt pracy z AWS to role. W tym przypadku konieczne jest zdefiniowanie roli, która pozwala wchodzić w interakcje z AWS IoT Core. 
			</aside>			
		</section>
		<section data-transition="none" data-background="#FFFFFF">
			<h3>Jak to "wyklikać" w AWS?</h3>
			<img data-src="img/AWS6Capture.PNG">
			<aside class="notes">
				Jak zdefiniować lambdę?
			</aside>			
		</section>
		<section data-transition="none" data-background="#FFFFFF">
			<h3>Jak to "wyklikać" w AWS?</h3>
			<img data-src="img/AWS7Capture.PNG">
			<aside class="notes">
				Lambda może być funkcją napisaną w pythonie. Na liście event znajdują się pola, które pojawiły się w JSON-ie, który został przesłany jako wiadomość z koszyka do brokera MQTT. W szczególności jest to pole "product".
			</aside>			
		</section>

		
        <section data-transition="none">
            <h3>Komunikacja z AWS IoT - biblioteka</h3>

			<div class="small">
					<pre><code>
from AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient
						 
class Communication:
	def __init__(self, host, port, rootCAPath, \
	  privateKeyPath, certificatePath):
	    # Init AWSIoTMQTTClient
		self.myAWSIoTMQTTClient = AWSIoTMQTTClient()
		self.myAWSIoTMQTTClient.configureEndpoint(host,\
			port)
		self.myAWSIoTMQTTClient.configureCredentials(\
			rootCAPath, privateKeyPath, \
			certificatePath)
					</code></pre>
			</div>
			<aside class="notes">
					Nazwę hosta bierzemy z AWS - jest to adres naszego brokera MQTT. Podobnie port - standardowo jest to 8883. <br><br>
					Potrzebujemy także certyfikatów Authority (CA), certyfikatu urządzenia i klucza prywatnego. Wszystkie 3 pobieramy z AWS. 
			</aside>
		</section>
		
        <section data-transition="none">
            <h3>Komunikacja z AWS IoT - biblioteka</h3>

			<div class="small">
					 <pre><code>
# AWSIoTMQTTClient connection configuration
self.myAWSIoTMQTTClient.configureAutoReconnectBackoffTime(1,\
	32, 20)
# Infinite offline Publish queueing
self.myAWSIoTMQTTClient.configureOfflinePublishQueueing(-1)  
# Draining: 2 Hz
self.myAWSIoTMQTTClient.configureDrainingFrequency(2)  
# 10 sec
self.myAWSIoTMQTTClient.configureConnectDisconnectTimeout(10)  
# 5 sec
self.myAWSIoTMQTTClient.configureMQTTOperationTimeout(5)  
					</code></pre>
			</div>
			<aside class="notes">
				configureAutoReconnectBackoffTime - pozwala skonfigurować zachowanie urządzenia przy ponownym łączeniu z brokerem MQTT; 1 = "base quiet time", 32 = "max quiet time"; kolejne próby połączenia po rozłączeniu są podejmowane kolejno w czasie min(2^n*base quiet time, max quiet time), gdzie n jest numerem próby; 20 = długość stabilnego połączenia - jeśli połączenie będzie stabilne przez taki czas, to resetuje się n<br><br>
				configureOfflinePublishQueueing - -1 oznacza, że nie kolejkujemy wiadomości w przypadku braku połączenia<br><br>
				configureDrainingFrequency - częstotliwość wysyłania wiadomości z kolejki po połączeniu w Hz. Tutaj nie ma znaczenia, bo nie kolejkujemy wiadomości, ale należy ten parametr ustawić przez nawiązaniem pierwszego połączenia.<br><br>
				configureConnectDisconnectTimeout - czas oczekiwania na rozłączenie. Należy ustawić przed pierwszym połączeniem.<br><br>
				configureMQTTOperationTimeout - czas oczekiwania na wykonanie operacji MQTT, czyli publish, subscribe, unsubscribe.
			</aside>
        </section>

        <section data-transition="none">
            <h3>Komunikacja z AWS IoT - biblioteka</h3>
			<div class="small">
					 <pre><code>

    def connect(self):
        self.myAWSIoTMQTTClient.connect()

    def subscribe(self, topic, callback):
        self.myAWSIoTMQTTClient.subscribe(topic, 1, callback)

    def publish(self, topic, message):
        self.myAWSIoTMQTTClient.publish(topic, message, 1)
					</code></pre>
			</div>
			<aside class="notes">
				myAWSIoTMQTTClient.subscribe - 1 = QoS; 0 = Fire and forget, 1 = At least once, 2 = Exactly once<br><br>
				myAWSIoTMQTTClient.publish - 1 = QoS
			</aside>
        </section data-transition="none">		
		
        <section data-transition="none">
            <h3>Demo</h3>
        </section>
		<!-- pliki demo.mov i demo2.mov -->
		<!--
        <section data-background="#000000" data-background-video="img/demo.mov" data-background-video-muted="" data-background-size="contain" data-transition="none">
        </section>
        <section data-background="#000000" data-background-video="img/demo2.mov" data-background-size="contain" data-transition="none">
        </section>
		-->
        <section data-transition="none" data-background="#FFFFFF">
            <h3>Lista rzeczy do zrobienia</h3>
            <ul>
                <li>
                    <div class="small">
                        <p class="fragment">uczenie YOLO z większą liczbą różnych produktów 
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">rozszerzenie funkcjonalności generowania rekomentacji 
                        <p>
                    </div>
                </li>
                <li>
                    <div class="small">
                        <p class="fragment">rozszerzenie sprzętu o baterię i obwód do jej ładowania 
                        <p>
                    </div>
                </li>
            </ul>
        </section>
        <section data-background="#FFFFFF" data-transition="none">
            <img width="900" height="230" data-src="img/architecture_high_level_6.png">
        </section>

		<section data-transition="none" data-background="#FFFFFF">
			<h3>AWS SageMaker</h3>
			<img data-src="img/SMschematCapture.PNG">
		</section>
		<section data-transition="none" data-background="#FFFFFF">
			<h3>Model do zastosowania - sieć Kohonena</h3>
			<img data-src="img/KohonenCapture.PNG">
			<aside class="notes">
				...algorytm do zastosowania w analizie koszykowej/asocjacji.
			</aside>
		</section>
		<section data-transition="none" data-background="#FFFFFF">
			<h3>Zbuduj własny koszyk!</h3>
                <div class="leftContent2">
                    <img width="420" data-src="img/kosz.png">
                </div>
                <div class="rightContent2">
					<p>
                    <ul>
						<li style="font-size:16pt">Intel Movidius Neural Compute Stick</li>
						<li style="font-size:16pt">Raspberry Pi 3 model B+ </li>
						<li style="font-size:16pt">UCTRONICS 3.5" 480 x 320 TFT LCD </li>
						<li style="font-size:16pt">karta micro-SD (16 GB+)</li>
						<li style="font-size:16pt">zasilacz USB 2A </li>
						<li style="font-size:16pt">obudowa do Raspberry Pi i ekranu 3.5” </li>
						<li style="font-size:16pt">plastikowy koszyk na zakupy</li>
						<li style="font-size:16pt">elementy montażowe (śruby, tuleje dystansowe, opaski zaciskowe)</li>
					</ul>
					</p>
					<p style="font-size:16pt">
						Kod do pobrania oraz niniejsza prezentacja: https://github.com/ai4change-yolo/
					</p>
                </div>
		</section>
        <section data-background="#FFFFFF" data-transition="none">
            <h3>Dziękujemy!</h3>
            <div class="leftContent2">
              <p class="small">Marcin Stachowiak</p>
            </div>
            <div class="rightContent2">
              <p class="small">Piotr Szajowski</p>
            </div>
			<img data-src="img/Capgemini.jpg">
        </section>
        <section data-background="#FFFFFF" data-transition="none">
		<h5>https://github.com/ai4change-yolo/</h5>
		</section>
    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [{
						src: 'plugin/markdown/marked.js'
					},
					{
						src: 'plugin/markdown/markdown.js'
					},
					{
						src: 'plugin/notes/notes.js',
						async: true
					},
					{
						src: 'plugin/highlight/highlight.js',
						async: true,
						callback: function() {
							hljs.initHighlightingOnLoad();
						}
					}
				]
			});










    </script>
</div>
</body>

</html>
